{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech tagging\n",
    "\n",
    "This part was produced using [Jupyter](http://jupyter.org).  \n",
    "If you are used to it, you can [download the corresponding notebook code from here](TP1-PoSTagging.ipynb). If not, no problem at all, this is not mandatory at all: simply proceed as usual in your favorite Python environment.\n",
    "\n",
    "### Preliminary steps\n",
    "\n",
    "Let us try NLTK with a simple example. The application here considered consist in associating \"_syntactic tags_\" (called \"_Part-of-Speech tags_\") to the words in a text; i.e. to determine the grammatical role of each word in the context of the sentence.\n",
    "\n",
    "The applications of PoS tagging are numerous. For instance:\n",
    "\n",
    "* help for \"lemmatization\" (obtain the wordsâ€™ canonical forms);\n",
    "* disambiguate words for higher level treatments (e.g. information extraction);\n",
    "* provide syntactic clues (\"roles\") for unknown words (\"guessers\"), ...\n",
    "\n",
    "PoS taggers usually reach a 95-99% performance level, depending on the language considered, the application and the granularity of the tag-set.\n",
    "\n",
    "More about Part-of-Speech tagging will be presented during the semester (Week 5). The purpose of the present exercise is simply to illustrate this NLP task and to check NLTK installation.\n",
    "\n",
    "In order to tag a sentence in NLTK from the python interpreter, you first need to download required models, if not done yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\leose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\leose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, simply proceed this way to actually tag some sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Your', 'PRP$'),\n",
       " ('sentence', 'NN'),\n",
       " ('comes', 'VBZ'),\n",
       " ('here', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag(sentence):\n",
    "    return nltk.pos_tag( nltk.word_tokenize( sentence ) )\n",
    "\n",
    "tag(\"Your sentence comes here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides some help about the tageset used. If not done yet, first download the required package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can require explaination about some tag, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset('RB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even some set of tags using regular expressions, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset('NN.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "Try tagging the following sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag(\"This is only a sample sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the Part-of-Speech tags? Do you understand them? Does it make senses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then try replacing the word \"_sample_\" with some unknown form, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag(\"This is only a xxx sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens? What do you get for \"_xxx_\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explaination:** Since \"_xxx_\" is not likely a word that the PoS-tagger has seen before, it will try to **guess** the part of speech tag (we will explore this topic in more detail during the semester, in the corresponding dedicated practical session). The most probable thing between a determinant and a nouns is an adjective, so this simple tagger will guess \"_xxx_\" to be an adjective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then try with some highly ambiguous sentence, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag(\"Time flies like an arrow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the obtained result consistent with one or the other possible interpretations of this sentence?  \n",
    "(reminder: make use of `nltk.help.upenn_tagset()` if needed)\n",
    "\n",
    "Does it correspond to your \"most intuitive interpretation\"?\n",
    "\n",
    "**Comment:** the tagger output is due to the limited scope of the algorithms used, this scope is limited for the sake of efficiency: $O(n)$ here, versus $O(n^3)$ for broader scope algorithms (CFG parser). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, try with a less ambiguous sentences, still containing some ambiguous words. For instance (prior to submiting it to the tager, ask yourself what are the ambiguous words; what ambiguities? Then proceed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag(\"This girl can beat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain why \"_can_\" and \"_beat_\" are correctly tagged as modal verb and verb, respectively, instead of nouns (given that both words are also sometimes nouns and nouns are more frequent than verbs)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comments\n",
    "\n",
    "**Note 1:** A parser can be used instead of a corpus-based POS-tagger to disambiguate words in context. But this demands more work on resource development (writing grammars), which is costly; and, the processing is also more costly: context-free parsing takes cubic time (w.r.t. sentence length) as opposed to PoS-tagging which takes linear time.\n",
    "\n",
    "This is a good illustration of the \"descriptive power\" as opposed to \"processing speed\" balance (i.e. compromize) presented in today's lecture.\n",
    "\n",
    "**Note 2:** Systematically disambiguating at each level of language (lexical, syntactic, semantic) is most of the time not necessary at all. It is often better to leave the disambiguation to a later, more informed, processing level, provided that complexity could be managed/handled. It is a more robust way to proceed. So, don't assume that at each step where you get some result, you have to decide on a unique one. Imagine solutions where you could ship/handle several solutions together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
